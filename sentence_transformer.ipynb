{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Berlin grocery data\n",
    "df = pd.read_csv('3_task_4_no_duplicates.csv', low_memory=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>IMAGE_URL</th>\n",
       "      <th>PRODUCT_PRICE</th>\n",
       "      <th>PRODUCT_PRICE_TREATED_OUTLIERS</th>\n",
       "      <th>PRODUCT_LINK</th>\n",
       "      <th>PRODUCT_INFORMATION_T</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>SUB_CATEGORY</th>\n",
       "      <th>PRICE_PER_KG/L</th>\n",
       "      <th>...</th>\n",
       "      <th>PRODUCT_REVIEWS</th>\n",
       "      <th>STORE_LINK</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>PRICE_PER_KG/L_UNIT</th>\n",
       "      <th>ENERGY_KJ</th>\n",
       "      <th>SUB_SUB_CATEGORY</th>\n",
       "      <th>PRODUCT_BRAND</th>\n",
       "      <th>PRODUCT_INFORMATION</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>NUTRITIONAL_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>Almdudler Original Herb Lemonade</td>\n",
       "      <td>https://imageproxy.wolt.com/menu/menu-images/6...</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>https://wolt.com/en/deu/berlin/venue/flink-kar...</td>\n",
       "      <td>Alpine herbal lemonade</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wolt: Flink Karl Liebknecht</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>Almdudler Sugar Free Herb Lemonade</td>\n",
       "      <td>https://imageproxy.wolt.com/menu/menu-images/6...</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>https://wolt.com/en/deu/berlin/venue/flink-kar...</td>\n",
       "      <td>Alpine herb lemonade without sugar with sweete...</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wolt: Flink Karl Liebknecht</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>267</td>\n",
       "      <td>almond butter brown 250g</td>\n",
       "      <td>https://static.mueller.de/markant_041044201797...</td>\n",
       "      <td>5.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>https://www.mueller.de/p/alnatura-mandelmus-br...</td>\n",
       "      <td>Product information An intensely aromatic pure...</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>Sweet spreads</td>\n",
       "      <td>23.96</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Muller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2559.002825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALNATURA</td>\n",
       "      <td>very unhealthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID                        PRODUCT_NAME  \\\n",
       "0  138    Almdudler Original Herb Lemonade   \n",
       "1  151  Almdudler Sugar Free Herb Lemonade   \n",
       "2  267            almond butter brown 250g   \n",
       "\n",
       "                                           IMAGE_URL  PRODUCT_PRICE  \\\n",
       "0  https://imageproxy.wolt.com/menu/menu-images/6...           2.24   \n",
       "1  https://imageproxy.wolt.com/menu/menu-images/6...           2.24   \n",
       "2  https://static.mueller.de/markant_041044201797...           5.99   \n",
       "\n",
       "   PRODUCT_PRICE_TREATED_OUTLIERS  \\\n",
       "0                            2.24   \n",
       "1                            2.24   \n",
       "2                            5.99   \n",
       "\n",
       "                                        PRODUCT_LINK  \\\n",
       "0  https://wolt.com/en/deu/berlin/venue/flink-kar...   \n",
       "1  https://wolt.com/en/deu/berlin/venue/flink-kar...   \n",
       "2  https://www.mueller.de/p/alnatura-mandelmus-br...   \n",
       "\n",
       "                               PRODUCT_INFORMATION_T         CATEGORY  \\\n",
       "0                             Alpine herbal lemonade  Food & Beverage   \n",
       "1  Alpine herb lemonade without sugar with sweete...  Food & Beverage   \n",
       "2  Product information An intensely aromatic pure...  Food & Beverage   \n",
       "\n",
       "    SUB_CATEGORY PRICE_PER_KG/L  ... PRODUCT_REVIEWS  STORE_LINK  \\\n",
       "0    Soft Drinks           1.99  ...             NaN         NaN   \n",
       "1    Soft Drinks           1.99  ...             NaN         NaN   \n",
       "2  Sweet spreads          23.96  ...             NaN         NaN   \n",
       "\n",
       "                    STORE_NAME  PRICE_PER_KG/L_UNIT    ENERGY_KJ  \\\n",
       "0  Wolt: Flink Karl Liebknecht                  NaN          NaN   \n",
       "1  Wolt: Flink Karl Liebknecht                  NaN          NaN   \n",
       "2                       Muller                  NaN  2559.002825   \n",
       "\n",
       "   SUB_SUB_CATEGORY  PRODUCT_BRAND  PRODUCT_INFORMATION MANUFACTURER  \\\n",
       "0               NaN            NaN                  NaN          NaN   \n",
       "1               NaN            NaN                  NaN          NaN   \n",
       "2               NaN            NaN                  NaN     ALNATURA   \n",
       "\n",
       "  NUTRITIONAL_LABEL  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2    very unhealthy  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns taken into consideration for modelling\n",
    "df_ = df[['PRODUCT_NAME', 'PRODUCT_PRICE_TREATED_OUTLIERS', 'PRODUCT_INFORMATION_T', \n",
    "       'CATEGORY', 'SUB_CATEGORY', 'SATURATED_FATTY_ACIDS', 'CARBOHYDRATES', 'SUGAR',\n",
    "       'PROTEIN', 'FIBER', 'SALT', 'FAT', 'INGREDIENTS', 'SUB_SUB_CATEGORY']].copy()\n",
    "\n",
    "# Reasons for not taking into consideration the following columns:\n",
    "# IMAGE_URL: Unless we compare the images themselves, which would be a very complex process in itself, \n",
    "#      adding this column would not bring us any benefit\n",
    "# PRODUCT_PRICE. PRODUCT_PRICE_TREATED_OUTLIERS will be used instead\n",
    "# PRODUCT_LINK: doesn't add valuable information\n",
    "# PRODUCT_QUANTITY: Upon inspection, this column information is highly unreliable\n",
    "# PRICE_PER_KG/L: Because the PRODUCT_QUANTITY column is unreliable, there's a high chance this one is also unreliable\n",
    "# ALLERGENS: Most of the values are missing\n",
    "# STORAGE_INFORMATION: Visual testing of the model's results proved that including this column would provide worse results\n",
    "# STORE_LINK, STORE_NAME: Wanted to use only the intrinsic characteristics of the products to create product similarities\n",
    "# PRODUCT_BRAND, MANUFACTURER: For most products, the brand is already present in the title, and matching products by brand\n",
    "#      instead of their characteristics was something we tried to avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove generic product information, like packaging information, warnings, or any other type of information\n",
    "#      that doesn't add specific details about the products and artificially creates similarities between products\n",
    "generic_text = [\n",
    "    \"nan\",\n",
    "    \"KL. II\",\n",
    "    \" No detailed information was provided about this product.\",\n",
    "    \"Westfalenland Fleischwaren GmbH has provided the above information.\",\n",
    "    \"The product design, the commercial class and the packer may differ when the goods are delivered. Please check the information on the respective product packaging and the delivery note, only these are binding.\",\n",
    "    \"DE-Ã?KO-006\", \"DE-Ã?KO-001\", \"DE-Ã?KO005\", \"DE-Ã?KO-005\", \"DE-Ã?KO-037\", \"DE-Ã?KO-013\",\n",
    "    \"Product information \",\n",
    "    \"Die Produktverpackung und zugehörigen Dokumente enthalten möglicherweise Angaben, die über die auf unserer Internetseite gemachten Angaben hinausgehen und/oder sich von ihnen unterscheiden. Wir empfehlen Ihnen daher, sich nicht allein auf die Angaben zu verlassen, die auf unserer Internetseite angezeigt werden, sondern sich vor Gebrauch der Ware stets auch sorgfältig die Etiketten, Warnhinweise und Anleitungen durchzulesen, die mit der Ware geliefert werden.\",\n",
    "    \"List of ingredients: \",\n",
    "    \"*\",\n",
    "    \"Schwartauer Werke has provided the above information.\",\n",
    "]\n",
    "for text in generic_text:\n",
    "    df_['PRODUCT_INFORMATION_T'] = df_['PRODUCT_INFORMATION_T'].str.replace(text, \"\", regex=False)\n",
    "    df_['INGREDIENTS'] = df_['INGREDIENTS'].str.replace(text, \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert empty strings to NaN values\n",
    "df_.replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we use text comparison in our model, it is more valuable to transform the numerical columns into categorical text.\n",
    "# And in this, way we also address the skewness identified in these columns\n",
    "num_to_cat_cols = {\"FAT\": df_['FAT'].describe()[\"75%\"], \n",
    "                   \"SALT\": df_['SALT'].describe()[\"75%\"], \n",
    "                   \"CARBOHYDRATES\": df_['CARBOHYDRATES'].describe()[\"75%\"], \n",
    "                   \"PROTEIN\": df_['PROTEIN'].describe()[\"75%\"], \n",
    "                   \"SUGAR\": df_['SUGAR'].describe()[\"75%\"], \n",
    "                   \"FIBER\": df_['FIBER'].describe()[\"75%\"], \n",
    "                   \"SATURATED_FATTY_ACIDS\": df_['SATURATED_FATTY_ACIDS'].describe()[\"75%\"]}\n",
    "\n",
    "def transform_col(x, col, low_upper_limit):\n",
    "    if np.isnan(x):\n",
    "        return 'Unknown ' + col.replace(\"_\", \" \")\n",
    "    if x == 0:\n",
    "        return 'No ' + col.replace(\"_\", \" \")\n",
    "    if x > 0 and x <= low_upper_limit:\n",
    "        return 'Low ' + col.replace(\"_\", \" \")\n",
    "    return 'High ' + col.replace(\"_\", \" \")\n",
    "\n",
    "for col, low_upper_limit in num_to_cat_cols.items():\n",
    "    df_.loc[:,col+'_BINNED'] = df_[col].apply(transform_col, args=(col, low_upper_limit))\n",
    "\n",
    "df_.drop(['FAT', 'SALT', 'FIBER', 'CARBOHYDRATES', 'PROTEIN', 'SUGAR', 'SATURATED_FATTY_ACIDS'], \n",
    "         axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the final list of text features we'll use to build our model and combine them in a single phrase\n",
    "text_features = ['PRODUCT_NAME', 'PRODUCT_INFORMATION_T', 'INGREDIENTS', \n",
    "       'SUB_CATEGORY', 'SUB_SUB_CATEGORY',\n",
    "       'FAT_BINNED', 'SALT_BINNED', 'CARBOHYDRATES_BINNED', 'PROTEIN_BINNED', \n",
    "       'SUGAR_BINNED', 'FIBER_BINNED', 'SATURATED_FATTY_ACIDS_BINNED']\n",
    "\n",
    "# text_features = ['PRODUCT_NAME', 'PRODUCT_INFORMATION_T', 'INGREDIENTS', 'SUB_CATEGORY', 'SUB_SUB_CATEGORY']\n",
    "\n",
    "df_['metadata'] = df_[text_features].apply(lambda x: '. '.join(x.dropna()), axis=1)\n",
    "\n",
    "# The CATEGORY column was not taken into consideration for the final modeling because it proved to produce worse results\n",
    "# This may be due to containing generic categories like Other, which would put very different products in the same category,\n",
    "#      and at the same time, a lot of products were put in the wrong category\n",
    "# On the contrary, SUB_CATEGORY, SUB_SUB_CATEGORY contain a lot of specific information about the products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\miniconda3\\envs\\recsys\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<?, ?B/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n",
      "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<?, ?B/s]\n",
      "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<?, ?B/s] \n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<?, ?B/s] \n",
      "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 1.59MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [01:31<00:00, 991kB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 24.7kB/s]\n",
      "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 910kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<?, ?B/s] \n",
      "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<?, ?B/s]\n",
      "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 895kB/s]\n",
      "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "# SentenceTransformers is a Python framework for state-of-the-art sentence, text, and image embeddings.\n",
    "# The all-MiniLM-L6-v2 model maps sentences & paragraphs to a 384-dimensional dense vector space\n",
    "# More sentence-transforming models can be found at: https://huggingface.co/sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings\n",
    "# TO DO: Split operation into chunks or use other method to keep track of progress, because this is a the lengthy process\n",
    "sentence_embeddings = model.encode(df_['metadata'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a version without product price\n",
    "np.save(\"final_matrix_f64_noP\", final_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the PRODUCT_PRICE_TREATED_OUTLIERS column and add it to the sentence_embeddings matrix\n",
    "def my_scaler(min_scale_num,max_scale_num,var):\n",
    "    return (max_scale_num - min_scale_num) * ( (var - min(var)) / (max(var) - min(var)) ) + min_scale_num\n",
    "\n",
    "df['PRODUCT_PRICE_TREATED_OUTLIERS_SCALED'] = my_scaler(0, 1, df['PRODUCT_PRICE_TREATED_OUTLIERS'].astype(float)) # scaled between 0,1\n",
    "\n",
    "final_matrix = np.hstack((sentence_embeddings, df[\"PRODUCT_PRICE_TREATED_OUTLIERS_SCALED\"].to_numpy().reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"final_matrix_f64\", final_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity\n",
    "# Split operation into chucks, otherwise it would be impossible to compute the operation because ~50GB of RAM would be required\n",
    "# For our application, we only need to keep the top 20 most similar products for each product instead of the complete 87157x87157 similarities\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "chunk = 10000\n",
    "steps = int(final_matrix.shape[0] / chunk)+1\n",
    "top_k = 21\n",
    "similarity_top_k = np.empty((final_matrix.shape[0],top_k), dtype=\"uint32\")\n",
    "\n",
    "for i in range(steps):\n",
    "    if ((i+1)*chunk) > final_matrix.shape[0]:\n",
    "        upper_bound = final_matrix.shape[0]\n",
    "    else:\n",
    "        upper_bound = (i+1)*chunk\n",
    "\n",
    "    similarity_matrix = cosine_similarity(final_matrix[i*chunk:upper_bound], final_matrix)\n",
    "\n",
    "    for j in range(similarity_matrix.shape[0]):\n",
    "        similarity_top_k[i*chunk+j] = np.argsort(similarity_matrix[j])[::-1][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"similarity_top_k\", similarity_top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456: 12.99 Nescafe Gold Mild 200G\n",
      "53631: 11.99 Nescafe Gold Mild Instant Coffee 200g\n",
      "53630: 11.99 Nescafe Gold Instant Coffee 200g\n",
      "53633: 6.49 Nescafe Gold Original instant coffee 100g\n",
      "3455: 7.99 Nescafe Gold Espresso 100G\n",
      "3458: 12.99 Nescafe Gold Original 200G\n",
      "3457: 7.49 Nescafe Gold Original 100G\n",
      "3453: 12.99 Nescafe Gold Crema 200G\n",
      "3446: 8.49 Nescafe Classic 200G\n",
      "3445: 5.79 Nescafe Classic 100G\n",
      "53561: 6.32 NESCAFÉ Gold Crema, instant coffee, 200g glass, pack of 3\n",
      "53492: 6.32 Nescafé Classic instant coffee beans (roasted medium dark), 200g\n",
      "53512: 2.99 Nescafé Gold Type Latte, Soluble Bean Coffee, Instant Coffee, Instant Coffee, 6 x 8 Servings\n",
      "53511: 2.99 Nescafé Gold type ESPRESSO, pack of 6 (6 x 100 g)\n",
      "53572: 24.85 NESCAFÉ Gold Type Cappuccino\n",
      "3447: 8.49 Nescafe Classic Crema 200G\n",
      "53603: 13.62 Nescafe Azera Americano Instant Coffee (100g) by Nescafe\n",
      "53634: 66.21 Nescafe Gold Premium Blend 6 x 200g\n",
      "53586: 19.08 NESCAFÉ Gold Type Latte Vanilla 4x(8x18.5g)\n",
      "53570: 12.99 NESCAFÉ GOLD Original, soluble bean coffee, instant coffee made from selected coffee beans, contains caffeine, pack of 1 (1 x 200g)\n",
      "53639: 7.29 Nescafe Gold Type Espresso 100g\n"
     ]
    }
   ],
   "source": [
    "# Print the top 20 similar product names\n",
    "product_id = 3456\n",
    "\n",
    "for i in similarity_top_k[product_id]:\n",
    "    print(\"{}: {} {}\".format(i, df.iloc[i]['PRODUCT_PRICE_TREATED_OUTLIERS'], df.iloc[i]['PRODUCT_NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
